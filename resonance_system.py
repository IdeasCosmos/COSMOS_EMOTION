"""
COSMOS EMOTION - Resonance ê³µëª… ì‹œìŠ¤í…œ
======================================

Part 3: Multi-Channel Resonance Detection System
- 5ì±„ë„ ê³µëª… ê°ì§€: Spectral, Phase, Harmonic, Semantic, Cross-Layer
- ì‹ ê²½ë§ í™•ì¥ ëŒ€ë¹„ ì„¤ê³„
- ì¦í­/ê°ì‡  íš¨ê³¼ ëª¨ë¸ë§
- ê³µëª… ê°„ì„­ íŒ¨í„´ ë¶„ì„

ğŸµ ìŒì•…ì  ë¹„ìœ :

ê³µëª…(Resonance)ì´ë€?
- ê°™ì€ ì£¼íŒŒìˆ˜ì˜ ì†Œë¦¬ê°€ ë§Œë‚˜ë©´ â†’ ì¦í­!
- ë°˜ëŒ€ ìœ„ìƒì´ ë§Œë‚˜ë©´ â†’ ìƒì‡„!
- í™”ìŒì´ ë§ìœ¼ë©´ â†’ ì•„ë¦„ë‹¤ìš´ ìš¸ë¦¼!

ê°ì •ë„ ë§ˆì°¬ê°€ì§€:
- ì—¬ëŸ¬ ì¸µì—ì„œ ê°™ì€ ê°ì • â†’ ê³µëª… ì¦í­
- ë°˜ëŒ€ ê°ì • ì¶©ëŒ â†’ ë³µí•© ê°ì • ìƒì„±
- íƒ€ì´ë° ì¼ì¹˜ â†’ ê°•ë ¬í•œ ì„íŒ©íŠ¸
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass, field
from collections import defaultdict, Counter
from scipy import signal
from scipy.spatial.distance import cosine
import math


# ============================================================================
# ê³µëª… ì±„ë„ ì •ì˜
# ============================================================================

class ResonanceChannel:
    """ê³µëª… ì±„ë„ ì—´ê±°í˜•"""
    SPECTRAL = "spectral"       # ì£¼íŒŒìˆ˜ ê³µëª… (ê°™ì€ ê°ì • ë°˜ë³µ)
    PHASE = "phase"             # ìœ„ìƒ ê³µëª… (íƒ€ì´ë° ì¼ì¹˜)
    HARMONIC = "harmonic"       # í™”ìŒ ê³µëª… (ê°ì • ì¡°í™”)
    SEMANTIC = "semantic"       # ì˜ë¯¸ ê³µëª… (ë¬¸ë§¥ ìœ ì‚¬ë„)
    CROSS_LAYER = "cross_layer" # ê³„ì¸µ ê°„ ê³µëª… (ìˆ˜ì§ ì—°ê²°)


@dataclass
class ResonanceSignal:
    """
    ê³µëª… ì‹ í˜¸ ì •ë³´
    
    ì‹ ê²½ë§ í™•ì¥ì„ ìœ„í•œ Feature Vector í¬í•¨:
    - 28ì°¨ì› ê°ì • ë²¡í„°
    - ê³µëª… ê°•ë„
    - ì£¼íŒŒìˆ˜/ìœ„ìƒ ì •ë³´
    - ë¬¸ë§¥ ì„ë² ë”©
    """
    position: int              # ìœ„ì¹˜ (ì‹œê°„ì¶•)
    layer: str                 # ê³„ì¸µ
    emotion_vector: np.ndarray # 28ì°¨ì› ê°ì • ë²¡í„°
    intensity: float           # ê°•ë„
    frequency: float           # ì£¼íŒŒìˆ˜ (ë°˜ë³µ íŒ¨í„´)
    phase: float              # ìœ„ìƒ (0 ~ 2Ï€)
    context_embedding: Optional[np.ndarray] = None  # ë¬¸ë§¥ ì„ë² ë”© (ì‹ ê²½ë§ìš©)
    
    # ë©”íƒ€ë°ì´í„°
    source: str = ""
    timestamp: float = 0.0
    
    def to_feature_vector(self) -> np.ndarray:
        """
        ì‹ ê²½ë§ í•™ìŠµìš© Feature Vector ìƒì„±
        
        êµ¬ì¡°:
        [emotion_vector(28), intensity(1), frequency(1), phase(1), 
         context_embedding(128)] = ì´ 159ì°¨ì›
        """
        features = [
            self.emotion_vector,                    # 28ì°¨ì›
            np.array([self.intensity]),             # 1ì°¨ì›
            np.array([self.frequency]),             # 1ì°¨ì›
            np.array([self.phase]),                 # 1ì°¨ì›
        ]
        
        if self.context_embedding is not None:
            features.append(self.context_embedding)  # 128ì°¨ì›
        else:
            features.append(np.zeros(128))           # ë¹ˆ ì„ë² ë”©
        
        return np.concatenate(features)


@dataclass
class ResonancePattern:
    """
    ê°ì§€ëœ ê³µëª… íŒ¨í„´
    """
    channel: str               # ê³µëª… ì±„ë„
    signals: List[ResonanceSignal]  # ì°¸ì—¬ ì‹ í˜¸ë“¤
    resonance_strength: float  # ê³µëª… ê°•ë„ (0.0 ~ 2.0+)
    amplification: float       # ì¦í­ë¥  (1.0 = ë³€í™” ì—†ìŒ)
    pattern_type: str          # íŒ¨í„´ ìœ í˜•
    confidence: float          # ì‹ ë¢°ë„
    
    # ì‹ ê²½ë§ í•™ìŠµìš©
    feature_matrix: Optional[np.ndarray] = None


# ============================================================================
# 1. Spectral Resonance (ì£¼íŒŒìˆ˜ ê³µëª…)
# ============================================================================

class SpectralResonanceDetector:
    """
    ì£¼íŒŒìˆ˜ ê³µëª… ê°ì§€ê¸°
    
    ì›ë¦¬:
    - ê°™ì€ ê°ì •ì´ ë°˜ë³µë˜ë©´ â†’ ì£¼íŒŒìˆ˜ ê³µëª… ë°œìƒ
    - ê³µëª… ê°•ë„ âˆ ë°˜ë³µ íšŸìˆ˜ Ã— ì¼ê´€ì„±
    
    ì‹ ê²½ë§ í™•ì¥:
    - LSTMìœ¼ë¡œ ì‹œí€€ìŠ¤ íŒ¨í„´ í•™ìŠµ
    - Attentionìœ¼ë¡œ ì¤‘ìš” ë°˜ë³µ ê°•ì¡°
    """
    
    def __init__(self, min_repetitions: int = 3, window_size: int = 10):
        self.min_repetitions = min_repetitions
        self.window_size = window_size
    
    def detect(
        self, 
        signals: List[ResonanceSignal]
    ) -> List[ResonancePattern]:
        """
        ì£¼íŒŒìˆ˜ ê³µëª… ê°ì§€
        
        ì•Œê³ ë¦¬ì¦˜:
        1. ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹ í˜¸ ë¶„ì„
        2. ê°™ì€ ê°ì •ì˜ ë°˜ë³µ íšŸìˆ˜ ê³„ì‚°
        3. ë°˜ë³µ íŒ¨í„´ì˜ ê·œì¹™ì„± í‰ê°€
        4. ê³µëª… ê°•ë„ ê³„ì‚°
        """
        patterns = []
        
        # ê°ì • ìœ í˜•ë³„ ì‹ í˜¸ ê·¸ë£¹í™”
        emotion_groups = defaultdict(list)
        
        for sig in signals:
            # ì£¼ ê°ì • ì¶”ì¶œ (ê°€ì¥ ê°•í•œ ê°ì •)
            dominant_emotion = self._get_dominant_emotion(sig.emotion_vector)
            emotion_groups[dominant_emotion].append(sig)
        
        # ê° ê°ì • ê·¸ë£¹ì— ëŒ€í•´ ê³µëª… ê²€ì‚¬
        for emotion_type, emotion_signals in emotion_groups.items():
            if len(emotion_signals) < self.min_repetitions:
                continue
            
            # ë°˜ë³µ íŒ¨í„´ ë¶„ì„
            repetition_pattern = self._analyze_repetition_pattern(
                emotion_signals
            )
            
            if repetition_pattern['is_resonating']:
                # ê³µëª… ê°•ë„ ê³„ì‚°
                resonance_strength = self._calculate_spectral_strength(
                    repetition_pattern
                )
                
                # ì¦í­ë¥  ê³„ì‚°
                amplification = 1.0 + (len(emotion_signals) - 2) * 0.15
                
                pattern = ResonancePattern(
                    channel=ResonanceChannel.SPECTRAL,
                    signals=emotion_signals,
                    resonance_strength=resonance_strength,
                    amplification=amplification,
                    pattern_type=f"repetition_{emotion_type}",
                    confidence=repetition_pattern['confidence'],
                    feature_matrix=self._create_feature_matrix(emotion_signals)
                )
                
                patterns.append(pattern)
        
        return patterns
    
    def _get_dominant_emotion(self, emotion_vector: np.ndarray) -> str:
        """ì£¼ ê°ì • ì¶”ì¶œ"""
        emotion_names = [
            'joy', 'sadness', 'anger', 'fear', 'disgust', 'surprise',
            'neutral', 'han', 'jeong', 'nunchi', 'hyeontta', 'menboong',
            'excitement', 'calmness', 'empathic_pain', 'amusement',
            'confusion', 'disappointment', 'guilt', 'shame', 'pride',
            'relief', 'hope', 'despair', 'nostalgia', 'contempt',
            'envy', 'gratitude'
        ]
        
        max_idx = np.argmax(emotion_vector)
        return emotion_names[max_idx] if max_idx < len(emotion_names) else 'unknown'
    
    def _analyze_repetition_pattern(
        self, 
        signals: List[ResonanceSignal]
    ) -> Dict:
        """
        ë°˜ë³µ íŒ¨í„´ ë¶„ì„
        
        Returns:
            {
                'is_resonating': bool,
                'regularity': float,  # ê·œì¹™ì„± (0~1)
                'confidence': float,
                'period': float       # ì£¼ê¸°
            }
        """
        if len(signals) < 2:
            return {'is_resonating': False, 'confidence': 0.0}
        
        # ìœ„ì¹˜ ê°„ê²© ê³„ì‚°
        positions = [sig.position for sig in signals]
        intervals = [positions[i+1] - positions[i] 
                    for i in range(len(positions)-1)]
        
        if not intervals:
            return {'is_resonating': False, 'confidence': 0.0}
        
        # ê°„ê²©ì˜ ê·œì¹™ì„± í‰ê°€ (í‘œì¤€í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ê·œì¹™ì )
        mean_interval = np.mean(intervals)
        std_interval = np.std(intervals)
        
        regularity = 1.0 / (1.0 + std_interval / (mean_interval + 1e-6))
        
        # ê³µëª… íŒì •
        is_resonating = (
            len(signals) >= self.min_repetitions and
            regularity > 0.5
        )
        
        return {
            'is_resonating': is_resonating,
            'regularity': regularity,
            'confidence': regularity,
            'period': mean_interval
        }
    
    def _calculate_spectral_strength(
        self, 
        pattern: Dict
    ) -> float:
        """
        ì£¼íŒŒìˆ˜ ê³µëª… ê°•ë„ ê³„ì‚°
        
        ê³µì‹:
            S = regularity Ã— log(1 + repetitions)
        """
        regularity = pattern['regularity']
        # repetitionsëŠ” íŒ¨í„´ì—ì„œ ì¶”ë¡ 
        repetitions = pattern.get('repetitions', 3)
        
        strength = regularity * np.log1p(repetitions)
        return float(strength)
    
    def _create_feature_matrix(
        self, 
        signals: List[ResonanceSignal]
    ) -> np.ndarray:
        """
        ì‹ ê²½ë§ í•™ìŠµìš© Feature Matrix ìƒì„±
        
        Shape: (n_signals, feature_dim)
        """
        return np.array([sig.to_feature_vector() for sig in signals])


# ============================================================================
# 2. Phase Resonance (ìœ„ìƒ ê³µëª…)
# ============================================================================

class PhaseResonanceDetector:
    """
    ìœ„ìƒ ê³µëª… ê°ì§€ê¸°
    
    ì›ë¦¬:
    - ê°ì • ë³€í™” íƒ€ì´ë°ì´ ì¼ì¹˜í•˜ë©´ â†’ ìœ„ìƒ ê³µëª…
    - ì—¬ëŸ¬ ê°ì •ì´ ë™ì‹œì— ë³€í™” â†’ ê°•í•œ ì„íŒ©íŠ¸
    
    ì‹ ê²½ë§ í™•ì¥:
    - Transformerì˜ Temporal Attention
    - ì‹œê°„ ì¶• ìƒê´€ê´€ê³„ í•™ìŠµ
    """
    
    def __init__(self, sync_threshold: float = 2.0):
        self.sync_threshold = sync_threshold  # ë™ì‹œ íŒì • ê¸°ì¤€ (ìœ„ì¹˜ ì°¨ì´)
    
    def detect(
        self, 
        signals: List[ResonanceSignal]
    ) -> List[ResonancePattern]:
        """
        ìœ„ìƒ ê³µëª… ê°ì§€
        
        ì•Œê³ ë¦¬ì¦˜:
        1. ì‹ í˜¸ë“¤ì„ ì‹œê°„ì¶•ìœ¼ë¡œ ì •ë ¬
        2. ê·¼ì ‘í•œ ì‹ í˜¸ë“¤ì„ í´ëŸ¬ìŠ¤í„°ë§
        3. ê° í´ëŸ¬ìŠ¤í„°ì˜ ìœ„ìƒ ë™ê¸°í™” ì •ë„ í‰ê°€
        4. ê³µëª… ê°•ë„ ê³„ì‚°
        """
        patterns = []
        
        if len(signals) < 2:
            return patterns
        
        # ìœ„ì¹˜ë³„ í´ëŸ¬ìŠ¤í„°ë§
        clusters = self._cluster_by_position(signals)
        
        for cluster in clusters:
            if len(cluster) < 2:
                continue
            
            # ìœ„ìƒ ë™ê¸°í™” ë¶„ì„
            sync_analysis = self._analyze_phase_synchronization(cluster)
            
            if sync_analysis['is_synchronized']:
                # ê³µëª… ê°•ë„ ê³„ì‚°
                resonance_strength = self._calculate_phase_strength(
                    sync_analysis
                )
                
                # ì¦í­ë¥  (ë™ì‹œ ë°œìƒ ì‹ í˜¸ ìˆ˜ì— ë¹„ë¡€)
                amplification = 1.0 + len(cluster) * 0.2
                
                pattern = ResonancePattern(
                    channel=ResonanceChannel.PHASE,
                    signals=cluster,
                    resonance_strength=resonance_strength,
                    amplification=amplification,
                    pattern_type="phase_sync",
                    confidence=sync_analysis['confidence'],
                    feature_matrix=self._create_feature_matrix(cluster)
                )
                
                patterns.append(pattern)
        
        return patterns
    
    def _cluster_by_position(
        self, 
        signals: List[ResonanceSignal]
    ) -> List[List[ResonanceSignal]]:
        """
        ìœ„ì¹˜ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
        
        DBSCANê³¼ ìœ ì‚¬í•œ ì ‘ê·¼
        """
        sorted_signals = sorted(signals, key=lambda s: s.position)
        
        clusters = []
        current_cluster = [sorted_signals[0]]
        
        for i in range(1, len(sorted_signals)):
            pos_diff = sorted_signals[i].position - sorted_signals[i-1].position
            
            if pos_diff <= self.sync_threshold:
                current_cluster.append(sorted_signals[i])
            else:
                if len(current_cluster) >= 2:
                    clusters.append(current_cluster)
                current_cluster = [sorted_signals[i]]
        
        if len(current_cluster) >= 2:
            clusters.append(current_cluster)
        
        return clusters
    
    def _analyze_phase_synchronization(
        self, 
        cluster: List[ResonanceSignal]
    ) -> Dict:
        """
        ìœ„ìƒ ë™ê¸°í™” ë¶„ì„
        
        Returns:
            {
                'is_synchronized': bool,
                'sync_strength': float,
                'confidence': float,
                'mean_phase': float,
                'phase_variance': float
            }
        """
        phases = [sig.phase for sig in cluster]
        
        # ìœ„ìƒ í‰ê·  (circular mean)
        mean_phase = np.arctan2(
            np.mean(np.sin(phases)),
            np.mean(np.cos(phases))
        )
        
        # ìœ„ìƒ ë¶„ì‚° (circular variance)
        phase_variance = 1 - np.sqrt(
            np.mean(np.sin(phases))**2 + np.mean(np.cos(phases))**2
        )
        
        # ë™ê¸°í™” ê°•ë„ (ë¶„ì‚°ì´ ì‘ì„ìˆ˜ë¡ ê°•í•¨)
        sync_strength = 1.0 - phase_variance
        
        is_synchronized = sync_strength > 0.7
        
        return {
            'is_synchronized': is_synchronized,
            'sync_strength': sync_strength,
            'confidence': sync_strength,
            'mean_phase': mean_phase,
            'phase_variance': phase_variance
        }
    
    def _calculate_phase_strength(self, analysis: Dict) -> float:
        """ìœ„ìƒ ê³µëª… ê°•ë„ ê³„ì‚°"""
        return analysis['sync_strength']
    
    def _create_feature_matrix(
        self, 
        signals: List[ResonanceSignal]
    ) -> np.ndarray:
        """Feature Matrix ìƒì„±"""
        return np.array([sig.to_feature_vector() for sig in signals])


# ============================================================================
# 3. Harmonic Resonance (í™”ìŒ ê³µëª…)
# ============================================================================

class HarmonicResonanceDetector:
    """
    í™”ìŒ ê³µëª… ê°ì§€ê¸°
    
    ì›ë¦¬:
    - ì¡°í™”ë¡œìš´ ê°ì • ì¡°í•© â†’ í™”ìŒ ê³µëª…
    - ì˜ˆ: joy + excitement, sadness + empathic_pain
    - ë¶ˆí˜‘í™” ê°ì§€ â†’ ë³µí•© ê°ì •
    
    ì‹ ê²½ë§ í™•ì¥:
    - Graph Neural Networkë¡œ ê°ì • ê°„ ê´€ê³„ í•™ìŠµ
    - Emotion Harmony Matrix í•™ìŠµ
    """
    
    def __init__(self):
        # ê°ì • ì¡°í™” ë§¤íŠ¸ë¦­ìŠ¤ (ì‚¬ì „ ì •ì˜ + í•™ìŠµ ê°€ëŠ¥)
        self.harmony_matrix = self._initialize_harmony_matrix()
    
    def _initialize_harmony_matrix(self) -> np.ndarray:
        """
        ê°ì • ì¡°í™” ë§¤íŠ¸ë¦­ìŠ¤ ì´ˆê¸°í™”
        
        28Ã—28 í–‰ë ¬: harmony_matrix[i][j] = iì™€ jì˜ ì¡°í™”ë„
        - 1.0: ì™„ì „ ì¡°í™” (ê°™ì€ ê³„ì—´)
        - 0.5: ì¤‘ë¦½
        - 0.0: ë¶ˆí˜‘í™” (ë°˜ëŒ€ ê°ì •)
        
        ì‹ ê²½ë§ìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥!
        """
        n_emotions = 28
        matrix = np.eye(n_emotions) * 1.0  # ëŒ€ê°ì„  1.0
        
        # ì¡°í™”ë¡œìš´ ê°ì • ìŒ (ì˜ˆì‹œ)
        harmonious_pairs = [
            (0, 12),   # joy - excitement
            (1, 14),   # sadness - empathic_pain
            (2, 10),   # anger - hyeontta
            (3, 16),   # fear - confusion
            (7, 8),    # han - jeong
            (22, 24),  # hope - relief
        ]
        
        for i, j in harmonious_pairs:
            matrix[i, j] = 0.9
            matrix[j, i] = 0.9
        
        # ë¶ˆí˜‘í™” ê°ì • ìŒ
        dissonant_pairs = [
            (0, 1),    # joy - sadness
            (0, 2),    # joy - anger
            (12, 13),  # excitement - calmness
            (22, 23),  # hope - despair
        ]
        
        for i, j in dissonant_pairs:
            matrix[i, j] = 0.1
            matrix[j, i] = 0.1
        
        return matrix
    
    def detect(
        self, 
        signals: List[ResonanceSignal]
    ) -> List[ResonancePattern]:
        """
        í™”ìŒ ê³µëª… ê°ì§€
        """
        patterns = []
        
        if len(signals) < 2:
            return patterns
        
        # ì‹ í˜¸ ìŒë³„ ì¡°í™”ë„ ê³„ì‚°
        for i in range(len(signals)):
            for j in range(i + 1, len(signals)):
                harmony_analysis = self._analyze_harmony(
                    signals[i], signals[j]
                )
                
                if harmony_analysis['is_harmonic']:
                    pattern = ResonancePattern(
                        channel=ResonanceChannel.HARMONIC,
                        signals=[signals[i], signals[j]],
                        resonance_strength=harmony_analysis['harmony_score'],
                        amplification=harmony_analysis['amplification'],
                        pattern_type=harmony_analysis['type'],
                        confidence=harmony_analysis['confidence'],
                        feature_matrix=self._create_feature_matrix(
                            [signals[i], signals[j]]
                        )
                    )
                    
                    patterns.append(pattern)
        
        return patterns
    
    def _analyze_harmony(
        self, 
        sig1: ResonanceSignal, 
        sig2: ResonanceSignal
    ) -> Dict:
        """
        ë‘ ì‹ í˜¸ì˜ ì¡°í™”ë„ ë¶„ì„
        """
        vec1 = sig1.emotion_vector
        vec2 = sig2.emotion_vector
        
        # ì£¼ ê°ì • ì¸ë±ìŠ¤
        idx1 = np.argmax(vec1)
        idx2 = np.argmax(vec2)
        
        # ì¡°í™” ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ ì¡°íšŒ
        harmony_score = self.harmony_matrix[idx1, idx2]
        
        # ê°•ë„ ê³ ë ¤
        combined_intensity = sig1.intensity * sig2.intensity
        
        # ì¡°í™” íŒì •
        is_harmonic = harmony_score > 0.7
        is_dissonant = harmony_score < 0.3
        
        if is_harmonic:
            pattern_type = "consonance"
            amplification = 1.0 + harmony_score * 0.5
        elif is_dissonant:
            pattern_type = "dissonance"
            amplification = 1.0  # ë¶ˆí˜‘í™”ëŠ” ì¦í­ ì—†ìŒ, ë³µí•©ê°ì • ìƒì„±
        else:
            pattern_type = "neutral"
            amplification = 1.0
        
        return {
            'is_harmonic': is_harmonic or is_dissonant,
            'harmony_score': harmony_score,
            'amplification': amplification,
            'type': pattern_type,
            'confidence': abs(harmony_score - 0.5) * 2  # ê·¹ë‹¨ì ì¼ìˆ˜ë¡ í™•ì‹ 
        }
    
    def _create_feature_matrix(
        self, 
        signals: List[ResonanceSignal]
    ) -> np.ndarray:
        """Feature Matrix ìƒì„±"""
        return np.array([sig.to_feature_vector() for sig in signals])


# ============================================================================
# 4. Semantic Resonance (ì˜ë¯¸ ê³µëª…)
# ============================================================================

class SemanticResonanceDetector:
    """
    ì˜ë¯¸ ê³µëª… ê°ì§€ê¸°
    
    ì›ë¦¬:
    - ë¬¸ë§¥ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê°ì •ë“¤ â†’ ì˜ë¯¸ ê³µëª…
    - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜
    
    ì‹ ê²½ë§ í™•ì¥:
    - BERT/GPT ì„ë² ë”© í™œìš©
    - Sentence Transformers
    """
    
    def __init__(self, similarity_threshold: float = 0.7):
        self.similarity_threshold = similarity_threshold
    
    def detect(
        self, 
        signals: List[ResonanceSignal]
    ) -> List[ResonancePattern]:
        """
        ì˜ë¯¸ ê³µëª… ê°ì§€
        """
        patterns = []
        
        if len(signals) < 2:
            return patterns
        
        # ëª¨ë“  ì‹ í˜¸ ìŒì— ëŒ€í•´ ìœ ì‚¬ë„ ê³„ì‚°
        for i in range(len(signals)):
            for j in range(i + 1, len(signals)):
                similarity = self._calculate_semantic_similarity(
                    signals[i], signals[j]
                )
                
                if similarity > self.similarity_threshold:
                    pattern = ResonancePattern(
                        channel=ResonanceChannel.SEMANTIC,
                        signals=[signals[i], signals[j]],
                        resonance_strength=similarity,
                        amplification=1.0 + similarity * 0.3,
                        pattern_type="semantic_match",
                        confidence=similarity,
                        feature_matrix=self._create_feature_matrix(
                            [signals[i], signals[j]]
                        )
                    )
                    
                    patterns.append(pattern)
        
        return patterns
    
    def _calculate_semantic_similarity(
        self, 
        sig1: ResonanceSignal, 
        sig2: ResonanceSignal
    ) -> float:
        """
        ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°
        
        ë°©ë²•:
        1. Context Embeddingì´ ìˆìœ¼ë©´ â†’ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        2. ì—†ìœ¼ë©´ â†’ ê°ì • ë²¡í„° ìœ ì‚¬ë„
        """
        # Context Embedding ì‚¬ìš©
        if (sig1.context_embedding is not None and 
            sig2.context_embedding is not None):
            
            similarity = 1 - cosine(
                sig1.context_embedding, 
                sig2.context_embedding
            )
        else:
            # ê°ì • ë²¡í„° ì‚¬ìš©
            similarity = 1 - cosine(
                sig1.emotion_vector, 
                sig2.emotion_vector
            )
        
        return float(similarity)
    
    def _create_feature_matrix(
        self, 
        signals: List[ResonanceSignal]
    ) -> np.ndarray:
        """Feature Matrix ìƒì„±"""
        return np.array([sig.to_feature_vector() for sig in signals])


# ============================================================================
# 5. Cross-Layer Resonance (ê³„ì¸µ ê°„ ê³µëª…)
# ============================================================================

class CrossLayerResonanceDetector:
    """
    ê³„ì¸µ ê°„ ê³µëª… ê°ì§€ê¸°
    
    ì›ë¦¬:
    - ì—¬ëŸ¬ ê³„ì¸µì—ì„œ ê°™ì€ ê°ì • â†’ ìˆ˜ì§ ê³µëª…
    - ê°•ë ¥í•œ ì¦í­ íš¨ê³¼
    
    ì‹ ê²½ë§ í™•ì¥:
    - Hierarchical Attention Network
    - Multi-Scale Feature Fusion
    """
    
    def __init__(self, min_layers: int = 3):
        self.min_layers = min_layers
    
    def detect(
        self, 
        signals: List[ResonanceSignal]
    ) -> List[ResonancePattern]:
        """
        ê³„ì¸µ ê°„ ê³µëª… ê°ì§€
        """
        patterns = []
        
        # ê³„ì¸µë³„ë¡œ ì‹ í˜¸ ê·¸ë£¹í™”
        layer_groups = defaultdict(list)
        for sig in signals:
            layer_groups[sig.layer].append(sig)
        
        if len(layer_groups) < self.min_layers:
            return patterns
        
        # ê° ê°ì • ìœ í˜•ë³„ë¡œ ê³„ì¸µ ê°„ ì¼ì¹˜ ê²€ì‚¬
        emotion_layer_map = defaultdict(lambda: defaultdict(list))
        
        for layer, layer_signals in layer_groups.items():
            for sig in layer_signals:
                dominant = self._get_dominant_emotion(sig.emotion_vector)
                emotion_layer_map[dominant][layer].append(sig)
        
        # ë‹¤ì¸µ ê°ì • ê²€ì‚¬
        for emotion_type, layers_dict in emotion_layer_map.items():
            if len(layers_dict) >= self.min_layers:
                # ê³µëª… ë°œìƒ!
                all_signals = []
                for layer_signals in layers_dict.values():
                    all_signals.extend(layer_signals)
                
                resonance_strength = len(layers_dict) / 5.0  # ìµœëŒ€ 5ì¸µ
                amplification = 1.0 + (len(layers_dict) - 2) * 0.3
                
                pattern = ResonancePattern(
                    channel=ResonanceChannel.CROSS_LAYER,
                    signals=all_signals,
                    resonance_strength=resonance_strength,
                    amplification=amplification,
                    pattern_type=f"multi_layer_{emotion_type}",
                    confidence=resonance_strength,
                    feature_matrix=self._create_feature_matrix(all_signals)
                )
                
                patterns.append(pattern)
        
        return patterns
    
    def _get_dominant_emotion(self, emotion_vector: np.ndarray) -> str:
        """ì£¼ ê°ì • ì¶”ì¶œ"""
        emotion_names = [
            'joy', 'sadness', 'anger', 'fear', 'disgust', 'surprise',
            'neutral', 'han', 'jeong', 'nunchi', 'hyeontta', 'menboong',
            'excitement', 'calmness', 'empathic_pain', 'amusement',
            'confusion', 'disappointment', 'guilt', 'shame', 'pride',
            'relief', 'hope', 'despair', 'nostalgia', 'contempt',
            'envy', 'gratitude'
        ]
        
        max_idx = np.argmax(emotion_vector)
        return emotion_names[max_idx] if max_idx < len(emotion_names) else 'unknown'
    
    def _create_feature_matrix(
        self, 
        signals: List[ResonanceSignal]
    ) -> np.ndarray:
        """Feature Matrix ìƒì„±"""
        return np.array([sig.to_feature_vector() for sig in signals])


# ============================================================================
# í†µí•© ê³µëª… ì‹œìŠ¤í…œ
# ============================================================================

class MultiChannelResonanceSystem:
    """
    5ì±„ë„ ê³µëª… ì‹œìŠ¤í…œ í†µí•©
    
    ì‹ ê²½ë§ í™•ì¥ ë¡œë“œë§µ:
    1. Phase 1: ê·œì¹™ ê¸°ë°˜ (í˜„ì¬)
    2. Phase 2: í•˜ì´ë¸Œë¦¬ë“œ (ê·œì¹™ + í•™ìŠµëœ ê°€ì¤‘ì¹˜)
    3. Phase 3: End-to-End í•™ìŠµ (Transformer + GNN)
    """
    
    def __init__(self):
        self.spectral_detector = SpectralResonanceDetector()
        self.phase_detector = PhaseResonanceDetector()
        self.harmonic_detector = HarmonicResonanceDetector()
        self.semantic_detector = SemanticResonanceDetector()
        self.cross_layer_detector = CrossLayerResonanceDetector()
        
        # ì±„ë„ë³„ ê°€ì¤‘ì¹˜ (í•™ìŠµ ê°€ëŠ¥!)
        self.channel_weights = {
            ResonanceChannel.SPECTRAL: 1.0,
            ResonanceChannel.PHASE: 1.2,
            ResonanceChannel.HARMONIC: 1.5,
            ResonanceChannel.SEMANTIC: 1.1,
            ResonanceChannel.CROSS_LAYER: 1.8  # ê°€ì¥ ì¤‘ìš”!
        }
    
    def detect_all_resonances(
        self, 
        signals: List[ResonanceSignal]
    ) -> Dict[str, List[ResonancePattern]]:
        """
        ëª¨ë“  ì±„ë„ì—ì„œ ê³µëª… ê°ì§€
        """
        results = {}
        
        print("\n" + "="*60)
        print("5ì±„ë„ ê³µëª… ê°ì§€ ì‹œì‘")
        print("="*60)
        
        # 1. Spectral
        print("\n[1/5] Spectral Resonance (ì£¼íŒŒìˆ˜ ê³µëª…)...")
        results[ResonanceChannel.SPECTRAL] = \
            self.spectral_detector.detect(signals)
        print(f"  ê°ì§€: {len(results[ResonanceChannel.SPECTRAL])}ê°œ")
        
        # 2. Phase
        print("\n[2/5] Phase Resonance (ìœ„ìƒ ê³µëª…)...")
        results[ResonanceChannel.PHASE] = \
            self.phase_detector.detect(signals)
        print(f"  ê°ì§€: {len(results[ResonanceChannel.PHASE])}ê°œ")
        
        # 3. Harmonic
        print("\n[3/5] Harmonic Resonance (í™”ìŒ ê³µëª…)...")
        results[ResonanceChannel.HARMONIC] = \
            self.harmonic_detector.detect(signals)
        print(f"  ê°ì§€: {len(results[ResonanceChannel.HARMONIC])}ê°œ")
        
        # 4. Semantic
        print("\n[4/5] Semantic Resonance (ì˜ë¯¸ ê³µëª…)...")
        results[ResonanceChannel.SEMANTIC] = \
            self.semantic_detector.detect(signals)
        print(f"  ê°ì§€: {len(results[ResonanceChannel.SEMANTIC])}ê°œ")
        
        # 5. Cross-Layer
        print("\n[5/5] Cross-Layer Resonance (ê³„ì¸µ ê°„ ê³µëª…)...")
        results[ResonanceChannel.CROSS_LAYER] = \
            self.cross_layer_detector.detect(signals)
        print(f"  ê°ì§€: {len(results[ResonanceChannel.CROSS_LAYER])}ê°œ")
        
        return results
    
    def calculate_total_amplification(
        self, 
        resonance_results: Dict[str, List[ResonancePattern]]
    ) -> Dict[str, float]:
        """
        ì´ ì¦í­ë¥  ê³„ì‚°
        
        ê³µì‹:
            A_total = Î (1 + w_i Ã— a_i)
            where w_i = ì±„ë„ ê°€ì¤‘ì¹˜, a_i = ì¦í­ë¥ 
        """
        total_amp = 1.0
        channel_contributions = {}
        
        for channel, patterns in resonance_results.items():
            if not patterns:
                channel_contributions[channel] = 0.0
                continue
            
            # í•´ë‹¹ ì±„ë„ì˜ í‰ê·  ì¦í­ë¥ 
            avg_amp = np.mean([p.amplification for p in patterns])
            
            # ê°€ì¤‘ì¹˜ ì ìš©
            weighted_amp = self.channel_weights[channel] * (avg_amp - 1.0)
            
            total_amp *= (1.0 + weighted_amp)
            channel_contributions[channel] = weighted_amp
        
        return {
            'total_amplification': total_amp,
            'channel_contributions': channel_contributions
        }
    
    def apply_resonance_to_emotion(
        self,
        base_emotion: np.ndarray,
        resonance_results: Dict[str, List[ResonancePattern]]
    ) -> np.ndarray:
        """
        ê³µëª… íš¨ê³¼ë¥¼ ê°ì •ì— ì ìš©
        """
        amplification = self.calculate_total_amplification(resonance_results)
        
        # ì¦í­ ì ìš©
        amplified_emotion = base_emotion * amplification['total_amplification']
        
        # ì •ê·œí™” (ì¤‘ë¦½ ì œì™¸)
        # ... (ìƒëµ)
        
        return amplified_emotion


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

if __name__ == "__main__":
    print("="*60)
    print("Multi-Channel Resonance System í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ ì‹ í˜¸ ìƒì„±
    test_signals = [
        ResonanceSignal(
            position=0,
            layer="WORD",
            emotion_vector=np.array([0.8, 0.1, 0, 0, 0, 0, 0.1] + [0]*21),
            intensity=0.8,
            frequency=1.0,
            phase=0.0,
            source="ê¸°ì˜ë‹¤"
        ),
        ResonanceSignal(
            position=5,
            layer="PHRASE",
            emotion_vector=np.array([0.7, 0.2, 0, 0, 0, 0, 0.1] + [0]*21),
            intensity=0.7,
            frequency=1.0,
            phase=0.1,
            source="ì •ë§ ê¸°ì˜ë„¤ìš”"
        ),
        ResonanceSignal(
            position=8,
            layer="SENTENCE",
            emotion_vector=np.array([0.9, 0.05, 0, 0, 0, 0, 0.05] + [0]*21),
            intensity=0.9,
            frequency=1.0,
            phase=0.0,
            source="ì˜¤ëŠ˜ì€ ìµœê³ ì˜ ë‚ "
        ),
    ]
    
    # ê³µëª… ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    resonance_system = MultiChannelResonanceSystem()
    
    # ê³µëª… ê°ì§€
    results = resonance_system.detect_all_resonances(test_signals)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ê³µëª… ê°ì§€ ê²°ê³¼")
    print("="*60)
    
    total_patterns = sum(len(patterns) for patterns in results.values())
    print(f"\nì´ {total_patterns}ê°œì˜ ê³µëª… íŒ¨í„´ ê°ì§€")
    
    for channel, patterns in results.items():
        if patterns:
            print(f"\n{channel}:")
            for i, pattern in enumerate(patterns, 1):
                print(f"  íŒ¨í„´ {i}:")
                print(f"    ê°•ë„: {pattern.resonance_strength:.3f}")
                print(f"    ì¦í­: Ã—{pattern.amplification:.2f}")
                print(f"    ì‹ ë¢°ë„: {pattern.confidence:.2%}")
    
    # ì´ ì¦í­ë¥  ê³„ì‚°
    amplification = resonance_system.calculate_total_amplification(results)
    
    print("\n" + "="*60)
    print("ì´ ì¦í­ íš¨ê³¼")
    print("="*60)
    print(f"ì´ ì¦í­ë¥ : Ã—{amplification['total_amplification']:.2f}")
    print("\nì±„ë„ë³„ ê¸°ì—¬ë„:")
    for channel, contribution in amplification['channel_contributions'].items():
        print(f"  {channel:15}: +{contribution:.2%}")
